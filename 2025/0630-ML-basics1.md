머신러닝 기초


## 1. 인공지능, 머신러닝, 딥러닝의 관계

**인공지능(AI)**: 인간의 학습, 추론, 지각능력을 인공적으로 구현하는 컴퓨터 과학 분야

**머신러닝(ML)**: 인공지능의 하위 분야, 데이터를 통해 함수를 학습하는 방법

**딥러닝(DL)**: 머신러닝의 하위 분야, 심층신경망 구조를 사용하는 특별한 머신러닝 방법

- **약인공지능(ANI)**: 정해진 특정 과제만 잘 수행하는 AI (현재 대부분의 AI)
- **강인공지능(AGI)**: 사람처럼 복합적 사고로 어떤 일이든 수행하는 AI (아직 실현되지 않음)

## 1-2. 머신러닝의 핵심 원리

### 기본 개념

머신러닝은 **함수를 학습**하는 과정이다.

**Input → 함수(모델) → Output**

머신러닝 모델을 만들려면 입력과 출력을

벡터나 행렬 같은 숫자 형태로 바꿔줘야 한다.

### 학습 과정

1. **파라미터(θ)를 가진 함수 공간 정의 (**데이터를 넣고 모델이 **예측)**
2. **데이터로 예측값과 실제값의 차이(손실) 측정**
3. **손실을 최소화하는 최적의 파라미터 찾기**

### 핵심 용어

- **Features(X)**: 입력 , 독립변수
- **Label(y)**: 정답 데이터, 목표값, Ground Truth
- **Prediction(ŷ)**: 모델이 예측한 값
- **Loss Function**: 예측값과 실제값의 차이를 측정하는 함수
- **Parameter(θ)**: 모델의 학습 가능한 변수

## 1-3. 데이터의 종류와 구분

### 정보 유형별 분류

- **정량적 정보**: 객관적, 측정 가능한 숫자
- **정성적 정보**: 주관적, 범주나 텍스트 형태

### 구조별 분류

- **정형 데이터**: 테이블 형태로 구조화된 데이터 (CSV, 엑셀 등)
- **비정형 데이터**: 구조화되지 않은 데이터 (텍스트, 이미지, 음성 등)

### 변수 유형별 분류

**수치형 변수**:

- 연속형: 소수점 가능 (키, 몸무게, 온도)
- 이산형: 정수만 가능 (개수, 나이)

**범주형 변수**:

- 명목형: 순서 없음 (성별, 색깔)
- 순위형: 순서 있음 (만족도, 등급)

## 1-4. 데이터의 수치적 표현 방법

### 범주형 데이터

**인덱싱**: 각 범주에 숫자 부여

- 성별: 여성(0), 남성(1)
- 지역: 서울(0), 경기(1), 강원(2)...

### 텍스트 데이터

- **글자 수준**: 각 글자를 숫자로 변환
- **단어 수준**: 각 단어를 숫자로 변환
- **자연어처리(NLP)**: 텍스트 데이터를 다루는 분야

### 이미지 데이터

**비트맵**: RGB 색상값을 0-255 숫자로 표현

- **컴퓨터 비전**: 이미지/동영상 데이터를 다루는 분야

### 음성 데이터

- **Raw Wave**: 음성 신호를 일정 주기로 샘플링
- **스펙트로그램**: 주파수별 신호 세기로 변환
- **음성처리**: 소리 데이터를 다루는 분야

## 1-5. 머신러닝의 확장성과 한계

### Universal Approximation Theorem

적절한 구조의 모델로 어떤 함수든 근사 가능하다.

### 한계점

1. **함수가 아닌 것은 학습 불가능**
2. **가능하다고 쉬운 것은 아님**
3. **문제가 함수로 잘 정의되어야 함**
    - Label Noise: 같은 입력에 다른 정답
    - Ambiguity: 모호한 정답

### 데이터셋 분할

- **Train Dataset**: 모델 학습용
- **Test Dataset**: 성능 평가용
- 일반적으로 랜덤 샘플링으로 분할

 모든 머신러닝 방법론은 어떤 모델 구조를 사용하고, 어떤 손실함수를 사용하며, 어떤 형태의 데이터를 다루는가에 따라 구분된다.

![image.png](attachment:590abdaf-eff3-4ca9-8c67-c6fd29a1001a:image.png)

![image.png](attachment:00832f0f-cf07-472d-a4b8-36f350754e95:image.png)

## 라벨 노이즈

머신러닝할 때 데이터에 문제가 있어서 학습이 잘 안되게 만드는 방해꾼

**대표적인 데이터 노이즈 종류:**

- **결측치:** 데이터가 비어있는 거.
- **이상치:** 혼자 튀는 이상한 값.
- **틀린 라벨:** 잘못된 분류 정보.
- **중복 샘플:** 똑같은 데이터가 여러 개 있는 거.
- **도메인 외의 샘플:** 우리가 관심 있는 범위 밖의 데이터

## 조용한 실패(Silent Failure)

모델 학습을 돌렸을 때

- 코드는 에러 없이 잘 돌아가고
- 손실 함수 값도 정상적으로 떨어지는 것처럼 보인다.

근데 몇 분이나 며칠 지나서 학습 끝나고 평가해보면,

**아예 쓸 수 없는 수준의 성능**을 보이는데 이걸 '조용한 실패' 라고 한다.

**이게 왜 위험한가?**

문제가 확인까지 엄청 오래 걸림.

프로젝트 진행이 늦어지니, 그냥 에러 나는 것보다 훨씬 더 위험

**발생하는 이유**

대부분은 **데이터나 전처리 문제** 때문에 발생

대처법

수시로 EDA를 통해 노이즈 확인 및 정제

모델 성능이 이상하면 노이즈 의심하기

노이즈 샘플 모으고 분류(어떤 노이즈 있는지 파악)

모은 노이즈 데이터 바탕으로 라벨링기준 세우기

세운 기준 전체 데이터셋에 적용(품질상승)

모호한 데이터 처리
개별 샘플 하나하나를 어떻게 처리할까 고민하기보다는,

**전체 데이터셋에 똑같이 적용할 수 있는 일관성 있는 기준을 세우는 게 엄청 중요**

# EDA (Exploratory Data Analysis : 탐색적 데이터 분석)

데이터 탐색해 특징,분포 이해하는 과정

●데이터셋의 기본적인 정보를 파악
●샘플을 랜덤추출해보며 패턴 파악
●각 변수의 통계량, 분포 확인
●변수간의 관계 파악

예시)

- **데이터가 총 몇 개야? 항목은 몇 개고 어떤 종류들이야?**
- **각 항목(변수)이 글자(범주형)인지 숫자(수치형)인지 뭔지?**
- 만약 숫자면, **어디부터 어디까지가 말이 되는 숫자**인지? (예: 가격인데 라던지)
- 만약 글자면, **어떤 종류의 글자들이** 들어있는지?
- 혹시 **정해진 형태가 없는 데이터**는 없는지? (사진, 음성 같은 거)

이렇게 보다 보면 (노이즈) 발견

- **값이 비어있는 곳은 없는지?**
- **말도 안 되는 범위의 값이 들어있는지?** (예: 가격인데 -5,800원 같은 거)

장점: 데이터 명확하게 이해, 빠른 가설 세우기 및 검증

하는일 :숨은 노이즈 찾기 , 편향된 데이터 파악

### 데이터셋의 편향(Bias)

데이터에 없는 부분 있거나 적어서 생기는 문제 (이러면 모델 학습 불가)

### 생존자 편향(Survivorship Bias)

돌아온 애들만 보고 판단해서 착각하는 것

![image.png](attachment:6e7cab14-ee12-4a73-b954-0e5ab2c8221b:image.png)

이상치와 결측치 파악

컴퓨터는 숫자를 저장할 수 있는 범위가 정해져 있다.

만약 그 범위를 넘어서는 숫자가 들어오면 오버플로우(Overflow)가 일어남

(엉뚱한 숫자, 에러 발생)

## 박스플롯(boxplot)

데이터를 시각적으로 보여주는 방법 중 하나
데이터를 딱 **5가지 중요한 숫자**로 요약해서 상자랑 선으로 그려줌

1.최솟값

2.사분위수 값

        Q1 : 25%

        중앙값 : 50%

        Q3 : 75%

1. 최댓값

![image.png](attachment:833ecf6b-5bc6-4426-96f3-6914affb6b39:image.png)

IQR :  Q3에서 Q1을 뺀 값인데, 상자의 높이와 같다.

데이터의 중간 50%가 얼마나 퍼져있는지 보여주는 범위라고 보면 됨

**수염 (whisker):** 상자 위아래로 쭉 뻗은 선.

이 선 바깥에 있는 점들은 '이상치'일 가능성이 높다고 보는 값들

![image.png](attachment:27a2342f-b633-4643-8029-90fc4b843fd4:image.png)

대한민국 연소득 평균은 5,828만원이나 중간값은 4,567만원이다 (2018년 기준)

소득은 불균형한, long-tailed 분포를 따른다고 추측 ( 빈부격차 심하다 )

### 비대칭도(왜도; skewness):

데이터 분포가 비대칭인 정도. 분포가 한쪽에 치우칠수록 절대값이 크다.

### 첨도(kurtosis):

데이터 분포가 뾰족한 정도. 샘플 분포가 한곳에 몰려있지 않고 퍼질수록 값이 작다.

![image.png](attachment:3d6f3306-dc46-47d9-9e6d-1d9636aa59b4:image.png)

## 상관계수 (Correlation)
데이터 변수 간 선형적인 연관성(상관관계)이 있는지를 나타내는 지표

![image.png](attachment:23fd16d6-8d9e-4439-87db-50750889b9d2:image.png)

1 에 가까우면 양 -1은 음. 0에 가까우면 거의 관계 없음

## 상관행렬 그림 (Correlation plot)
데이터셋 내 모든 변수간의 상관관계를 한개의 행렬로 나타낸 것

![image.png](attachment:e2b11d19-cd61-4656-a2b1-6b5371d8f038:image.png)

빨간색에 가까울수록 서로 양의 관련성이 크고

파란색에 가까울수록 서로 음의 관련성이 크다는 뜻

노란색에 가까울수록 별로 관련이 없다

# 데이터의 전처리

피쳐 스케일(scale)의 조정

데이터 값의 크기를 맞춰주는 것

- 숫자 크기가 너무 차이 나면(예: 1000 vs 0.001) 작은 숫자가 무시될 수 있다.
- **표준화**는 평균 0, 표준편차 1로 맞춰주고
- **정규화**는 제일 작은 값을 0, 제일 큰 값을 1로 맞춰준다.

이렇게 하면 데이터 값들이 공평하게 다뤄지고, 데이터의 모양(분포)도 그대로 유지

20250630

---
