## 순차적 데이터

어떠한 순서를 가지는 데이터로, 순서가 바뀌면 의미를 잃는다.

시계열 데이터

동일한 간격으로 연속된 시각에서 취한 순차적 데이터


시계열 데이터는 규칙성분과 불규칙 성분으로 나뉜다.

**규칙성분:** 주기적으로 나타나는 패턴

**불규칙성분:** 예측하기 어려운, 무작위적인 부분

## 시계열 데이터의 구성성분 3가지

추세 (trend)

데이터가 시간이 지남에 따라 쭉 올라가거나 내려가는 장기적인 움직임

예) 인구 수,  전 세계 평균 기온

계절성 (Seasonality)

1년, 1주일처럼 일정한 주기로 반복되는 패턴

평일/주말 손님 수, 낮과 밤의 기온

순환성 (Cyclicity)

계절성보다 더 긴 주기로 불규칙하게 반복되는 패턴

엘니뇨,라니냐 현상

### 시계열 데이터의 특성

시계열 예측은 과거가 미래에 영향을 주기 때문에 가능

보통 머신러닝은 데이터들이 서로 독립적이라고 가정하지만

시계열 데이터는 과거와 현재가 연결되어 있어 독립적이지 않다.

### 독립 항등 분포

(IID; Independent and Identically Distributed)

데이터들이 **서로 독립적**이고 **모두 같은 확률 분포**에서 나왔을 때 IID라고 함
대부분의 머신러닝 모델이 이 IID를 가정하고 만들어짐
IID를 가정할 수 없는 데이터는 일반적인 머신러닝 모델을 그대로 쓰기 어렵다.

### 자기 상관(Autocorrelation)

한 시계열 데이터 안에서 자기 자신과 다른 시점의 데이터가 

얼마나 관련이 있는지를 나타냄
**과거 데이터가 현재 데이터에 얼마나 영향을 미치는지** 숫자로 보여줌

시차(Lag)라는 개념이 중요. 시차 1의 자기 상관이 높다는 건 

"오늘 데이터가 어제 데이터랑  밀접하다는 의미

### 마르코프 속성 (Markov property)

미래는 현재에만 달려있고, 과거는 중요하지 않다는 특성
어떤 현상이 다음 상태로 변할 때, 오래된 과거 상태는 필요 없고 

**바로 직전의 현재 상태만 알면 충분하다**는 의미


마르코프 속성을 가정하고 예측하면 '마르코프 모델'이라고 부름

마르코프 속성을 만족하는 이산 시간(뚝뚝 끊어지는 시간) 랜덤 프로세스를 

'마르코프 체인’ 이라고 부름

### 시계열의 정상성(Stationarity)

**정상성 데이터 (Stationary):** 

시간과 상관없이 데이터가 만들어지는 **패턴이나 특성이 변하지 않고 일정하게 유지되는** 시계열 데이터
**예시:** 화이트 노이즈 (White noise)는 대표적인 정상성 데이터

**비정상성 데이터 (Non-stationary):** 

반대로 시간이 지남에 따라 데이터가 만들어지는 **패턴이나 특성(분포) 자체가 계속 변하는** 시계열 데이터
**예시:** **주식 가격**이 대표적인 비정상성 데이터

## 시계열 데이터 분석 과정

시계열 데이터는 'IID가 아닌' 특성 때문에 특별한 주의가 필요

1.정상성 확인

2.**전처리 (정상성 변환):** 만약 정상성이 아니라면, 데이터의 평균이 일정해지고, 분산이나 상관관계가 시간에 따라 변하지 않도록 변환 작업실시

3.모델 구성

## 시계열 데이터의 분석 방법

| 구분 | 분석 방법 | 설명 |
| --- | --- | --- |
| **주파수 활용 분석** | **푸리에(Fourier) 분석** | 데이터를 여러 주파수의 파동으로 분해해서 숨겨진 주기성(반복되는 패턴)을 찾아냄. |
|  | **스펙트럼 밀도 분석** | 어떤 주파수 성분이 특히 강한지 파악해서 데이터의 주기성을 자세히 분석함. |
|  | **웨이블렛(Wavelet) 분석** | 푸리에 분석보다 더 복잡하거나 갑자기 변하는 패턴, 또는 짧은 구간의 변화를 탐지하는 데 유용함. |
| **시간 변화 분석** | **자기회귀모델 (AR)** | 과거 자기 자신의 데이터 값이 현재 데이터 값에 얼마나 영향을 주는지 분석하고 미래를 예측함. |
|  | **이동평균 (MA)** | 일정 기간 동안의 데이터 평균을 계속 계산해서 데이터의 큰 흐름(추세)이나 변동을 부드럽게 파악함. |
|  | **추세 (Trend) 분석** | 데이터가 시간이 지남에 따라 장기적으로 쭉 증가하거나 감소하는 경향을 찾아냄. |
|  | **성분분해 (Decomposition)** | 시계열 데이터를 추세, 계절성, 불규칙성 같은 여러 기본 요소로 나누어 각각을 따로 분석함. |

## 시계열 데이터의 분해

시계열 데이터의 성분분해
시계열 데이터를 예측or 계절성 영향을 조절하기 위해, 

데이터를 몇 가지 기본 성분으로 **쪼개서 보는 것**

특히, 주어진 시계열 데이터를 

계절성, 추세, 불규칙 성분으로 분해하는 것을 계절성 분해 라고 함


이동 평균 모델 (Moving Average model)
데이터를 **일정 기간씩 묶어 평균을 내서** 원래 데이터의 **들쭉날쭉한 짧은 변화들을 없애고, 큰 흐름(추세)을 보기 좋게 만드는 방법**

예) 5일간 데이터가 2, 5, 1, 9, 11 이라면,

 가장 최근 2일 평균 (9+11)/2 = 10 이 다음 값을 예측하는 데 쓰이는 식

자기회귀 모델 (Auto-Regressive model)

**과거의 내 모습**을 가지고 **미래의 내 모습**을 예측하는 방법
**지금(t)의 데이터를 예측**하기 위해, **바로 이전(t-1)이나 그 전전(t-2),**

 **또는 그 이상(p만큼)의 과거 데이터**들을 참고해서 예측 모델을 만드는 것

---

### 모델 평가의 구성 요소

정성평가(Qualitative Evaluation)
모델에 **데이터를 넣고 나온 결과물을 사람이 직접 보고 판단**
"음, 이 그림은 실제 같네" 같은 식으로 **느낌이나 경험에 따라 평가**

정량 평가 (Quantitative Evaluation)
모델의 성능을 **숫자로 정확하게 나타내는 방법**

'정확도 95%', '오차율 3%'처럼 수치를 사용해 모델이 얼마나 좋은지 판단

핵심은 둘 다 중요

정량평가 지표 (Evaluation Metric)
모델이 **정답을 얼마나 맞췄는지 숫자로 보여주는 지표**

손실함수 역시 목표값과 현재 값의 차이로 계산되므로 일종의  성능 지표


모델의 성능을 평가하고 학습시키는 데는 **다양한 손실 함수와 지표**가 사용됨

MAE (Mean Absolute Error)

평균 절대 오차. 예측값과 실제값의 차이를 절댓값으로 바꿔서 평균
 

MSE (Mean Squared Error)

평균 제곱 오차. 예측값과 실제값의 차이를 제곱해서 평균

RMSE (Root Mean Squared Error)

평균 제곱근 오차. MSE에 제곱근을 씌운 것.

교차 엔트로피

분류 모델에서 쓰이는 손실 함수 

모델이 정답 범주를 얼마나 확실하게 예측했는지 측정


이건 MSE가 MAE보다 **큰 오차에 더 민감하게 반응한다**는 의미

별도의 평가 데이터셋이 필요한 이유

모델은 학습할 때 쓴 데이터에 대해 손실 함수 값을 

거의 0에 가깝게 만들면서 너무 잘 외움 

그래서 처음 보는 데이터가 들어왔을 때 얼마나 잘 맞출지는 알 수 없다. 

이를 해결 하기 위해 별도 평가용 데이터셋으로 일반화 성능을  측정함

일반화 성능이란?

모델이 새로운 데이터에 대해서도 얼마나 정확하게 예측하는지 말함

검증용 데이터셋

실제로는 8:1:1정도로 분할해 학습용/검증용/평가용 으로 사용하는 것이 흔함

모델의 복잡도(Complexity, Capacity)

모델이 더 복잡하고 어려운 데이터까지 학습할 수 있는 용량

파라미터(변수)의 수가 많을수록 복잡도 커짐

**복잡도가 무조건 높다고 좋은 건 아님**


모델의 복잡도는 데이터를 학습하는 능력이지만

너무 복잡하면 예측 성능이 떨어짐

과적합 (Overfitting)
모델이 학습할 때 쓴 **데이터의 패턴만 너무 과하게 외워버리는 현상**

처음 보는 '새로운 데이터'가 들어오면 예측을 전혀 못하게 되는 상황

정규화 (Regularization)

과적합 문제를 막기 위한 방법론
모델이 학습 데이터를 너무 완벽하게 외우지 못하도록 

**모델의 복잡도가 필요 이상으로 커지지 않도록 '제한'을 두는 기술**

### 데이터 누출(Data Leakage)

모델 성능이 '비정상적으로 높게' 측정되는 문제를 말함

모델 학습에 쓰여야 할 데이터가 실수로 평가용 데이터셋에도 들어가 버리는 경우 발생

원래 데이터셋에 똑같거나 아주 비슷한 데이터가 많이 들어있을 때 생김

### 데이터셋 분할 방법

2분할 방법
전체 데이터를 2개로 나눠서 학습용과 검증용으로 사용

3분할 방법
전체 데이터를 **3개로 나눠서 학습용,검증용,평가용으로 활용**

보통은 이 3분할 방법을 많이 사용

**데이터 양이 너무 적거나, 따로 평가용 데이터셋이 굳이 필요 없다고 판단될 때는 2분할 방법**을 쓰기도 함


 k-fold 교차검증(Cross Validation)
데이터를 **여러 개의 똑같은 크기(k개, 보통 3~10개)로 쪼개(fold)**

그리고 이 쪼갠 것들 중에서 **하나씩 돌아가면서 '검증용 데이터'로 쓰고,** 

**나머진 학습용 데이터로 사용해 모델을 학습/검증하는 과정을 총 k번 반복**

k번 반복해서 얻은 **모든 결과를 평균** 내서 모델의 최종 성능을 추정


장점 : 데이터 효율적 사용 , 편향 줄이기

단점 : 많은 리소스 필요

내삽 (Interpolation)

모델이 배운 범위 안에서 새로운 데이터 예측

외삽 (Extrapolation)

범위를 넘어서 새로운 데이터 예측

모델의 내삽 능력을 보려면 '검증용 데이터셋'을 쓰고, 

외삽 능력까지 보려면 '평가용 데이터셋'을 쓴다.


### 데이터셋의 규모에 따른 분할 방법

**전체 데이터의 크기가**

- **적당하다면 (1000~10000개 정도)**
    - 7:1:2로 3분할하여 사용한다.
- **너무 작다면 (100개 정도)**
    - 2분할해서 50:50으로 사용하거나
    - 또는 5-fold 교차 검증을 사용한다.
- **너무 크다면 (1,000,000장 이상)**
    - 3분할, 970,000 : 10,000 : 20,000 (학습 : 검증 : 평가)
    - 평가, 검증용 데이터셋은 어느 정도 샘플 수가 확보된 이후로는
    - 기계적으로 양을 늘리기보다는 품질을 관리하는 것이 훨씬 중요하다.

다만, 데이터셋이 어느 정도 커야 적당한지는 문제, 모델의 복잡도에 따라 상대적으로 판단해야 하며, 여기에 적어둔 샘플 수는 참고용으로만 사용한다.

---

데이터셋 내에 특정 클래스에 해당하는 샘플이 매우 적을 경우 

단순 랜덤으로 분할했을 때 희귀한 클래스가 평가용 데이터에서 누락되어, 평가용 데이터셋의 대표성이 떨어질 가능성이 커진다.

이런 경우, 데이터셋을 클래스별로 나누어 각각을 랜덤분할 후 다시 합치는,
계층적 분할 방법을 사용
