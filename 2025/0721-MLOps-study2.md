### **Rule-based (규칙 기반) 방식을 고르는 상황:**

1. **규칙이 명확하고 안정적일 때:**
    - **예시:** 세금 계산, 은행 계좌 잔고 확인, 시스템 로그인 시 비밀번호 3회 오류 시 잠금, 신호등 제어.
    - **설명:** 이런 경우는 '만약 ~이면 반드시 ~해야 한다'는 규칙이 아주 명확하고, 시간이 지나도 잘 변하지 않아. 예외 상황도 거의 없거나, 미리 예측해서 규칙으로 만들 수 있어.
2. **데이터가 부족하거나 패턴이 단순할 때:**
    - **예시:** 아주 초기 단계의 시스템, 새로운 비즈니스 모델이라 과거 데이터가 거의 없을 때.
    - **설명:** ML은 학습할 데이터가 많아야 하는데, 데이터가 없으면 ML 모델을 만들 수 없어. 혹은 문제가 너무 단순해서 몇 가지 규칙만으로 충분히 해결될 때도 굳이 ML을 쓸 필요가 없어.
3. **높은 설명 가능성(Explainability)이 필수적일 때:**
    - **예시:** 법적 규제가 있는 금융 거래 승인, 의료 진단 보조 시스템, 민감한 개인 정보 처리.
    - **설명:** 왜 그런 결과가 나왔는지 '블랙박스'처럼 알 수 없는 ML 모델보다, '어떤 규칙 때문에 이런 결정이 내려졌다'라고 명확하게 설명할 수 있어야 하는 상황에서는 규칙 기반 방식이 훨씬 유리해.
4. **초기 개발 속도가 중요하고, 복잡성이 크지 않을 때:**
    - **예시:** MVP(Minimum Viable Product)를 빠르게 만들어서 시장 반응을 보고 싶을 때.
    - **설명:** 규칙이 몇 개 안 되는 간단한 시스템은 빠르게 구축할 수 있어.

---

### **ML-based (머신러닝 기반) 방식을 고르는 상황:**

1. **규칙을 명확하게 정의하기 어렵거나, 너무 복잡할 때:**
    - **예시:** 스팸 메일 분류 (스팸 패턴이 너무 다양하고 계속 변함), 이미지에서 고양이/개 구분, 사람의 목소리를 텍스트로 변환, 추천 시스템.
    - **설명:** 사람이 일일이 "이런 패턴의 글자는 스팸, 저런 패턴의 글자는 아님"이라고 규칙을 만들기가 불가능에 가까운 상황이야. 데이터 안에 숨어있는 복잡한 패턴을 기계가 스스로 학습해야 할 때 ML이 빛을 발해.
2. **방대한 양의 양질의 데이터가 있을 때:**
    - **예시:** 수억 장의 이미지 데이터, 수만 시간의 음성 데이터, 수년간의 고객 구매 이력 데이터.
    - **설명:** ML 모델은 데이터가 많을수록 똑똑해져. 충분한 학습 데이터가 있어야 좋은 성능의 모델을 만들 수 있어.
3. **시스템의 유연성과 적응력이 중요할 때 (새로운 상황에 대응해야 할 때):**
    - **예시:** 새로운 유형의 사이버 공격 감지, 유행에 따라 계속 바뀌는 패션 트렌드 예측, 신조어 등장에 따른 자연어 처리 능력 개선.
    - **설명:** 세상은 계속 변하고, 그에 따라 시스템도 적응해야 할 때가 많아. ML 모델은 새로운 데이터를 학습해서 스스로 업데이트하고 진화할 수 있어.
4. **최고의 성능이 중요하고, 약간의 설명 불가능성을 감수할 수 있을 때:**
    - **예시:** 대규모 서비스의 정확도 높은 추천, 의료 영상 진단 (전문가 검수 가능 시), 번역 서비스.
    - **설명:** '왜 이런 추천을 했는지' 완벽하게 설명하기 어렵더라도, '사용자가 실제로 더 만족하는' 결과가 더 중요할 때 ML이 선택돼.

---

**결론적으로, 두 방식 중 하나를 결정할 때는 이 질문들을 스스로에게 던져보는 게 좋아:**

- **규칙을 명확하게 정의할 수 있는가?** (Yes: Rule-based, No: ML-based)
- **충분하고 양질의 데이터가 있는가?** (Yes: ML-based, No: Rule-based)
- **결과에 대한 설명이 반드시 필요한가?** (Yes: Rule-based 유리, No: ML-based도 가능)
- **시스템이 계속해서 변화에 적응해야 하는가?** (Yes: ML-based, No: Rule-based도 가능)
- **얼마나 높은 정확도나 성능이 필요한가?** (높을수록 ML-based 유리)

## 두 방식을 **섞어서 쓰는 경우**가 굉장히 많아. 이런 방식을 **하이브리드(Hybrid) 방식**

**하이브리드 방식의 일반적인 예시:**

1. **Rule-based로 1차 필터링/분류 후 ML-based로 상세 분석:**
    - **예시:** 스팸 메일 필터링.
        - **Rule-based:** "제목에 '광고' 또는 '대출'이라는 단어가 있으면 일단 스팸으로 분류" (명확하고 쉬운 규칙으로 일차적으로 걸러냄)
        - **ML-based:** 1차 필터링을 통과한 메일 중 남은 것들을 가지고, 과거 스팸 데이터로 학습된 ML 모델이 더 복잡한 패턴(문장 구조, 발신자 평판 등)을 분석해서 최종 스팸 여부를 판단.
    - **장점:** 규칙으로 쉽게 걸러낼 수 있는 건 빠르게 처리하고, 복잡한 것만 ML이 처리해서 효율성을 높일 수 있어. ML 모델의 부담을 줄여 성능을 향상시키는 데도 도움이 돼.
2. **ML-based 모델의 결과를 Rule-based로 보정/강화:**
    - **예시:** 금융 사기 탐지.
        - **ML-based:** 고객의 거래 패턴 데이터를 학습해서 사기 가능성을 예측하는 ML 모델.
        - **Rule-based:** "ML 모델이 사기라고 판단해도, 만약 고객이 본인 휴대폰으로 OTP 인증을 완료했다면 최종적으로 사기가 아니다" (ML 모델이 예측하지 못한 중요한 예외 사항이나 반드시 지켜야 할 정책을 규칙으로 추가하여 안전성 확보)
    - **장점:** ML 모델의 예측을 기반으로 하되, 놓쳐서는 안 되는 중요한 정책이나 예외 상황을 규칙으로 강제해서 시스템의 신뢰성과 안정성을 높일 수 있어. 설명 가능성이 필요한 부분에 규칙을 적용할 수도 있지.
3. **ML-based 모델이 Rule-based 규칙을 생성하거나 최적화:**
    - **예시:** 산업 공정 제어 시스템.
        - **ML-based:** 센서 데이터를 학습해서 최적의 장비 작동 조건을 예측하는 ML 모델.
        - **Rule-based:** ML 모델이 예측한 최적 조건을 바탕으로, 장비 제어를 위한 규칙(예: "온도가 몇 도 이상이면 밸브를 몇 % 열어라")을 자동으로 생성하거나 업데이트.
    - **장점:** 복잡한 시스템의 규칙을 수동으로 정의하기 어려울 때, ML의 학습 능력을 활용해서 규칙을 자동으로 찾아내고 개선할 수 있어.
4. **초기에는 Rule-based, 점진적으로 ML-based로 전환:**
    - **예시:** 신규 서비스의 고객 응대 챗봇.
        - **초기 Rule-based:** 자주 묻는 질문(FAQ)에 대한 답변은 간단한 규칙으로 처리.
        - **ML-based로 전환:** 챗봇이 운영되면서 쌓이는 실제 고객 질문 데이터를 가지고, 자연어 처리(NLP) 기반의 ML 모델을 학습시켜 점점 더 복잡하고 다양한 질문에 대응할 수 있도록 발전.
    - **장점:** 데이터가 부족한 초기에는 빠르게 시스템을 구축하고, 데이터가 쌓이면서 점진적으로 ML의 장점을 활용하여 시스템을 고도화할 수 있어.

이렇게 두 방식을 섞어 쓰면, 각 방식의 장점을 극대화하고 단점을 보완하여 더 유연하고 강력하며 효율적인 시스템을 만들 수 있어. 실제 많은 인공지능 서비스나 자동화 시스템에서 이 하이브리드 방식을 채택

머신러닝 모델은 데이터과학자가 주도적으로 개발

체크리스트가 없으면 놓치는 경우가 생김




머신러닝 엔지니어가 알아야 할 부분

데이터 과학자 입장

모델 개발은 데이터 과학자가 주도적으로 함

모델 개발에 필요한 거 : 파이썬 파이토치 넘파이 판다스 등등

자원은 cpu xx코어, gpu xx급 xxG, 메모리 xxG…

필요하면 여러 모델 동시학습 할 수 있으면 좋겠다…

실험 결과도 통합해서 편하게 관리 할 수 있으면 좋겠네…

모델 개발은 데이터 과학자(비개발자)가 진행하기 때문에

필요한 환경과 도구들을 엔지니어가 세팅해주어야 함

데이터 과학자는 일반적으로 **엔지니어링**에 익숙하지 않으며

**모델 실험에만 집중하고 싶어함**




| 분류 기준 (Category) | 뜻 (Meaning) | 대표적인 것 (Key Examples) |
| --- | --- | --- |
| **DATA MANAGEMENT** | 데이터 관리의 전 과정 | 데이터 레이블링 (정답 달기), 데이터 버전 관리 (변경 이력 관리) |
| **MODELLING** | AI 모델을 만들고 학습시키고 평가하는 과정 | 피처 엔지니어링 (새로운 정보 만들기), 모델 학습, 실험 기록 관리 |
| **CONTINUOUS DEPLOYMENT** | 개발된 모델을 실제 서비스에 배포하고 관리/업데이트하는 과정 | 모델 서비스화 (배포), 배포된 모델 검증 |
| **COMPUTING MANAGEMENT** | 모델 개발 및 운영에 필요한 컴퓨터 자원 관리 과정 | 자원 할당, 자원 유연하게 늘리기 |


엔지니어들이  이 입출력요소가 뭔지 최소한 알아야 한다.

- 모델 학습 시 입출력 요소
- **핵심:** 인공지능 모델을 학습시킬 때, 모델 안팎으로 어떤 데이터나 값들이 오가는지에 대해 설명하고 있어.
    - **데이터셋:** 모델을 학습시키는 데 사용하는 데이터 덩어리
    - **각종 파라미터:**
        - **모델 파라미터:** 모델이 학습을 통해 스스로 조절하는 값들로, 인공신경망의 가중치(weight)나 편향(bias) 같은 거야.
        - **수행 파라미터:** 모델을 실행하는 애플리케이션에 필요한 값들 (예: 날짜).
        - **하이퍼파라미터:** 모델 학습 전에 사람이 직접 설정해주는 값들 (예: 학습률, 배치 크기, 레이어 수 등).
    - **학습된 모델(가중치 파일):** 학습이 끝나고 나면, 모델이 학습한 결과물로 저장되는 파일이야.
    - **모델의 출력 데이터(추론 결과):** 학습된 모델이 새로운 데이터를 보고 내놓는 예측 결과야.
    - **모델 지표:** 모델의 성능이 얼마나 좋은지 나타내는 수치들 (예: 정확도, 정밀도, 재현율 등).
    - **수행 로그:** 모델 학습 과정에서 기록되는 모든 정보들.
    
- 여기서 개발자가 알아야 할 것들을 정리
    1. **데이터셋**:
        - **이해:** 모델을 학습시키는 데 사용하는 데이터 덩어리라는 걸 알아야 해.
        - **개발자 관점:** 어떤 데이터를 어떻게 모으고(데이터 수집 파이프라인), 전처리하고, 모델에 효율적으로 넣어줄지 **데이터 파이프라인 구축 및 관리**에 대한 이해가 필요해. 데이터 형식을 맞추고, 데이터 불균형 등을 해결하는 능력도 중요해.
    2. **각종 파라미터**:
        - **모델 파라미터:** 레이어의 가중치(weight)와 편향(bias) 같은 모델이 학습을 통해 스스로 조절하는 값들이라는 걸 알아야 해.
        - **개발자 관점:** 이 파라미터들이 모델 내부에 어떻게 저장되고, 학습 과정에서 어떻게 업데이트되는지 **모델 구조와 학습 메커니즘**에 대한 깊은 이해가 중요해. 텐서플로우나 파이토치 같은 프레임워크를 통해 이 파라미터들을 다루는 방법을 알아야 해.
        - **수행 파라미터:** 날짜 같은 애플리케이션 수행에 필요한 동작 매개변수라는 걸 알아야 해.
        - **개발자 관점:** 모델을 애플리케이션에 통합할 때, **어떻게 모델에 필요한 외부 값을 전달하고, 모델의 동작을 제어할지**에 대한 설계를 담당하게 돼. API 연동이나 배치 스크립트 작성 시 이런 파라미터를 효과적으로 다루는 기술이 필요해.
        - **하이퍼파라미터:** 학습률, 배치 크기, 레이어 수 등 모델 학습 관련 사전 설정 값이라는 걸 알아야 해.
        - **개발자 관점:** 최적의 모델 성능을 찾기 위해 이 하이퍼파라미터들을 어떻게 조합하고 실험할지 (하이퍼파라미터 튜닝) **자동화된 실험 관리 도구(예: MLflow, Weights & Biases)**를 활용하는 방법을 알아야 해.
    3. **학습된 모델 (가중치 파일)**:
        - **이해:** 학습이 끝나면 모델의 결과물로 저장되는 파일이라는 걸 알아야 해.
        - **개발자 관점:** 학습된 모델(가중치 파일)을 **어떻게 효율적으로 저장하고(모델 레지스트리), 버전 관리하며, 배포 환경에 적재할지**에 대한 기술이 중요해. 모델을 서비스 형태로 배포하기 위한 기술(컨테이너화, API 서버 구축 등)도 필요하고.
    4. **모델의 출력 데이터 (추론 결과)**:
        - **이해:** 학습된 모델이 새로운 데이터를 보고 내놓는 예측 결과라는 걸 알아야 해.
        - **개발자 관점:** 모델이 추론 결과를 낼 때 **응답 시간(레이턴시)을 최소화**하고, **많은 요청을 처리할 수 있도록(확장성)** 모델 서빙 아키텍처를 설계하고 구현하는 능력이 중요해.
    5. **모델 지표**:
        - **이해:** 모델의 성능이 얼마나 좋은지 나타내는 수치라는 걸 알아야 해.
        - **개발자 관점:** 모델이 배포된 후 **실시간으로 이 지표들을 모니터링하고 시각화**하는 시스템을 구축해야 해. 성능 저하(데이터 드리프트, 모델 드리프트)가 발생했을 때 빠르게 감지하고 알림을 보낼 수 있는 시스템을 만드는 역할도 중요해.
    6. **수행 로그**:
        - **이해:** 모델 학습 과정에서 기록되는 모든 정보라는 걸 알아야 해.
        - **개발자 관점:** **모델 학습 및 추론 과정의 로그를 체계적으로 수집, 저장, 분석**할 수 있는 시스템을 구축해야 해. 이를 통해 문제가 발생했을 때 원인을 파악하고 디버깅하는 데 활용할 수 있지.
    
    요약하자면, 개발자는 단순히 코드를 짜는 것을 넘어, **모델이 개발되고 배포되며 운영되는 전체 ML 파이프라인과 관련된 기술적인 부분을 설계, 구현, 관리하는 능력**이 중요
    
# 배포

모델 개발 완료! 데이터과학자가 이제 모델 배포하려 한다.

데이터과학자가 실험했던 환경과 동일하게 세팅하는게 굉장히 중요

태스크 ~~ 있고, 태스크 순서는 ~~로 수행해야 해요

태스크별 수행 인자로는 ~~ 옵션은 이렇고…

모델 학습이랑 추론단계에서 하이퍼파라미터는 …이 들어가야해요

카테고리별로 모델이 n개 나와야해서 총 n번 수행해야돼요

데이터는 n시간 마다 n만큼 수집해야 해요

모델의 배포는 데이터과학자가 실험한 수 많은 모델중

특정 버전의 모델을 받아서 배포하게 됨

데이터과학자가 겪는 문제

어떤 모델이 베스트 모델이였지?

엊그제 돌렸던 모델이 몇 번째 모델이지?

n번째 모델 프로덕션에 베포해주세요 

어떤 버전의 모델이라도 빠르고 일관성 있게 배포할 수 있는 환경이 중요

여기서 발생하는 문제

모델 실험환경과 프로덕션 환경이 같지 않다.


데이터 과학자가 자기 컴퓨터에서 모델을 잘 돌렸다고 해서 그 모델이 서비스 환경에서도 문제없이 돌아간다는 보장이 없다는 것을 시각적으로 보여주는 그림


- 그림설명
    - **제목:** 모델 배포
    - **핵심 내용:** 이 슬라이드는 머신러닝 모델을 실제로 서비스에 적용(배포)할 때 **무엇을 고려해야 하는지, 그리고 그 책임이 어떤 엔지니어링 팀에 있는지**를 보여주고 있어.
        - **ML 엔지니어링 (ML Engineering) 담당 고려사항:**
            - **모델의 일관성 및 버전 관리:** 모델이 개발 환경에서처럼 배포된 후에도 똑같이 작동하는지 확인하고, 여러 모델 버전들을 체계적으로 관리하는 거야.
        - **데이터 엔지니어링 (Data Engineering) 담당 고려사항:**
            - **데이터의 스키마 및 버전:** 모델에 들어가는 데이터의 구조(형식)가 일관적인지 확인하고, 데이터 버전도 관리해서 모델과 데이터가 잘 맞도록 하는 거야.
            - **태스크 수행 파라미터:** 모델이 돌아갈 때 필요한 특정 입력값이나 설정값들을 잘 넘겨주고 관리하는 것이지.
        - **데브옵스 엔지니어링 (DevOps Engineering) 담당 고려사항:** (이 부분들은 주로 모델을 시스템에 통합하고 운영하는 것과 관련이 있어.)
            - **서빙 방식(REST API, gRPC, on-device 등):** 모델을 서비스할 때 어떤 방법으로 사용자나 다른 시스템이 모델을 이용할 수 있게 할지 정하는 거야 (예: 웹 API 형태로 제공할지, 특정 기기에 직접 탑재할지).
            - **워크플로우 수행 시간:** 모델이 예측을 하거나 특정 작업을 수행하는 데 걸리는 전체 시간을 관리해서 너무 오래 걸리지 않도록 하는 것이지.
            - **컴퓨팅 자원 요구사항:** 모델을 돌리는 데 필요한 CPU, GPU, 메모리 같은 컴퓨터 자원을 정확히 파악하고 준비하는 거야.
            - **확장성 및 탄력성:** 사용량이 갑자기 늘어나거나 문제가 발생했을 때도 시스템이 잘 버티고 안정적으로 작동하도록 만드는 능력을 말해.
            - **응답 지연 요구사항:** 모델이 요청을 받고 결과를 돌려주는 데 허용되는 최대 시간을 관리하는 거야. 너무 느리면 사용자가 불편하겠지?
            - **모니터링과 로깅:** 배포된 모델이 잘 작동하는지 항상 감시하고, 발생하는 모든 활동과 오류를 기록해서 문제가 생겼을 때 빠르게 알아내고 해결할 수 있도록 하는 거야.
    
    요약하면, 이 그림은 **모델을 실제 서비스에 내보낼 때는 여러 엔지니어링 팀이 각자의 역할을 가지고 협력해서 모델이 잘 돌아가도록 해야 한다**는 걸 보여주는 거야.
    

현업은 구분없이 모델 배포 담당자가 다 하게된다.

모델 수행 환경의 일관성 어떻게 유지하나?

컨테이너화




도커라는 도구를 통해 컨테이너화를 시킬 수 있다

독립된 환경으로 만들고 파일 생성. 하나의 스냅샷으로 만든다.(이미지생성)

이 스냅샷이 있으면 어느 컴퓨터든 환경을 똑같이 설정 가능하다.

같은 실험결과를 얻을 수 있음

컨테이너화 된 모델은 언제 어디서 수행하나?



아파치 에어플로우

큐브플로우

엠엘플로우

워크플로우는 일반적으로 컨테이너에서 수행되므로

수행결과는 휘발되니 결과를 별도의 저장소에 저장해야함

(출력 데이터, 학습된 모델, 모델지표, 수행로그 등)



스토리지저장소에선 아마존3를 제일 많이씀 

저렴하고 확장성, 안정성이 매우 뛰어나서, 모델 학습용 대량 데이터셋, 학습된 모델 파일, 로그 등을 저장하는 데 거의 표준처럼 사용

- **MySQL (마이SQL):** 가장 널리 사용되는 **관계형 데이터베이스(RDBMS)**야. 데이터가 표(테이블) 형태로 정형화되어 있고, 데이터 간의 관계가 명확할 때 주로 사용돼. 웹 서비스, 기업용 애플리케이션 등 광범위한 분야에서 오랫동안 표준처럼 쓰이고 있어.
- **MongoDB (몽고DB):** 대표적인 **NoSQL 데이터베이스** 중 하나야. 데이터가 유연한 문서(Document) 형태로 저장되기 때문에, 데이터의 구조가 자주 바뀌거나 정형화되지 않은 데이터를 다룰 때 매우 유리해. 특히 대용량의 비정형 데이터를 저장하고 빠르게 처리해야 하는 서비스에서 많이 사용돼.
- **Amazon DynamoDB (아마존 다이나모DB):** AWS 클라우드에서 빠르고 유연한 NoSQL 데이터베이스를 제공하며, 대규모 서비스에서 고성능을 요구할 때 많이 사용돼.






- **데이터 준비:** 오프라인 데이터를 가져와서 데이터 추출, 분석, 준비 과정을 거쳐.
- **모델 학습 및 검증:** 준비된 데이터로 모델을 학습시키고 성능을 평가하고 검증해. 이 모든 과정이 수동으로 진행돼.
- **모델 배포:** 학습된 모델은 모델 레지스트리에 등록되고, 모델 서빙을 통해 예측 서비스로 제공돼.


- MLOps 1단계 'ML 파이프라인 자동화' 설명
    
    
    ---
    
    **MLOps 1단계: ML 파이프라인 자동화 (MLOps Level 1: ML Pipeline Automation)**
    
    이 단계는 복잡한 기계 학습(ML) 모델을 만들고 운영하는 과정을 **컴퓨터가 대부분 알아서 처리하도록 자동화한 시스템**이야. 이전 단계보다 훨씬 빠르고 효율적으로 모델을 만들고 서비스할 수 있지.
    
    **핵심은 크게 두 가지 흐름으로 나눌 수 있어:**
    
    1. **연구실 같은 개발/실험 자동화 (Orchestrated Experiment):**
        - 여기서는 사람이 데이터를 분석하고, 모델을 개발하고, 테스트하는 과정들을 체계적으로 자동화해서 진행해.
        - 이렇게 개발된 모델의 코드나 정보는 잘 정리해서 보관하고, 나중에 실제 서비스에 적용될 준비를 해.
    2. **공장 같은 운영/배포 자동화 (Automated Pipeline):**
        - 이 부분이 가장 핵심적인 자동화 흐름이야.
        - **시작점:**
            - **트리거(Trigger):** 특정 조건(예: 새 데이터 도착, 정해진 시간)이 되면 "자, 이제 시작!" 하고 전체 자동화 과정을 작동시키는 방아쇠 역할을 해.
            - **피처 스토어(Feature Store):** 모델 학습이나 예측에 필요한 데이터를 미리 잘 정리해서 모아둔 '데이터 창고'야. 여기서 필요한 데이터를 바로 가져와서 써.
        - **자동화된 과정:**
            - **데이터 추출(Data extraction):** 필요한 데이터만 뽑아내.
            - **데이터 유효성 검사(Data validation):** 뽑아낸 데이터에 문제가 없는지 확인해.
            - **데이터 준비(Data preparation):** 모델이 학습하기 좋게 데이터를 다듬고 정리해.
            - **모델 학습(Model training):** 준비된 데이터로 모델을 가르쳐.
            - **모델 유효성 검사(Model validation):** 학습된 모델이 잘 작동하는지 확인해.
            - **모델 평가(Model evaluation):** 모델의 성능을 최종적으로 평가해.
        - **최종 목적지:**
            - **CD: 모델 서빙(CD: Model serving):** 평가가 끝난 좋은 모델을 사람들이 바로 쓸 수 있도록 자동으로 배포하고 서비스하는 단계야.
            - **예측 서비스(Prediction service):** 모델 서빙을 통해 배포된 모델이 실제 사용자에게 예측 결과를 제공하는 서비스가 돼.
    
    **중요한 특징 (순환 구조):**
    
    - 이 시스템은 단순히 한 방향으로만 가는 게 아니라, **성능 모니터링(Performance monitoring)**을 통해 예측 서비스가 잘 작동하는지 계속 지켜봐.
    - 만약 문제가 생기거나 성능이 떨어지면, 그 정보를 바탕으로 다시 **데이터 분석** 단계로 돌아가서 모델을 개선하는 **지속적인 순환 구조**를 가지고 있어.
    
    **결론:** MLOps 1단계는 ML 모델 개발부터 운영까지의 많은 부분을 **자동화된 파이프라인**으로 연결하여, 효율성을 높이고 모델을 지속적으로 개선할 수 있게 만든 시스템이라고 보면 돼.
    

MLOps 0단계 1단계 차이

| 구분 | MLOps 0단계: 수동 프로세스 (Manual Process) | MLOps 1단계: ML 파이프라인 자동화 (ML Pipeline Automation) |
| --- | --- | --- |
| **자동화 수준** | **거의 없음.** 모든 과정(데이터 준비, 모델 학습, 배포 등)을 사람이 직접 수동으로 함. | **상당히 자동화됨.** 대부분의 과정이 컴퓨터가 알아서 처리하는 파이프라인으로 연결됨. |
| **주요 작업** | - 데이터 수동 준비- 모델 수동 학습 및 평가- 모델 수동 배포 및 관리 | - 데이터 추출/검증/준비 자동화- 모델 학습/평가 자동화- 모델 배포 자동화 (CD: Model serving) |
| **개발/운영** | 개발과 운영이 명확히 분리되지 않고, 수동 작업으로 인해 병목 현상이 많음. | 개발(오케스트레이션된 실험)과 운영(자동화된 파이프라인)이 분리되고, 효율적인 협업이 가능함. |
| **피드백 루프** | 거의 없음. 문제가 생기면 사람이 처음부터 다시 시작해야 함. | **있음.** 성능 모니터링을 통해 문제가 감지되면 자동으로 데이터 분석 단계로 돌아가 개선함 (순환 구조). |
| **속도/효율성** | 느리고 비효율적임. 모델 업데이트나 배포에 시간이 오래 걸림. | 빠르고 효율적임. 모델 업데이트와 배포가 신속하게 이루어짐. |
| **목표** | 일단 모델을 만들고 배포하는 것에 중점. | 모델을 지속적으로 개선하고, 안정적으로 운영하며, 빠르게 배포하는 것에 중점. |

한 줄로 요약하면,
**0단계는 사람이 모든 걸 직접 하는 '수작업' 방식이고, 1단계는 컴퓨터가 대부분의 과정을 알아서 처리해주는 '자동화된 공장' 방식이라고 생각하면 돼.**


| 구분 | MLOps 1단계: ML 파이프라인 자동화 (ML Pipeline Automation) | MLOps 2단계: CI/CD 파이프라인 자동화 (CI/CD Pipeline Automation) |
| --- | --- | --- |
| **자동화 대상** | **ML 모델을 만들고 배포하는 과정** 자체를 자동화. | **ML 파이프라인 시스템을 만들고 배포하는 과정**까지 자동화. |
| **핵심 추가점** | - | **CI/CD (지속적 통합/지속적 배포)** 개념이 도입됨. |
| **의미** | 모델 학습부터 서빙까지 자동화. | **모델을 학습시키는 '자동화 시스템' 자체**를 자동으로 만들고 업데이트함. |
| **결과** | 모델 업데이트가 빠르고 효율적. | **ML 시스템 전체의 안정성과 신뢰성**이 훨씬 높아짐. |

**쉽게 말해:**

- **1단계:** 모델을 만드는 공장(파이프라인)이 **자동으로 돌아가게** 만드는 거야.
- **2단계:** 모델을 만드는 공장(파이프라인)이 **스스로 업그레이드되고 관리되게** 만드는 거야. 즉, 공장 자체를 자동화하는 거지.

그래서 2단계는 1단계보다 훨씬 더 고도화되고 안정적인 MLOps 시스템이라고 볼 수 있어.


실습 해보기

1. 모델 및 서빙 요구사항


인력
○ ML Engineer 1
○ Data Scientist 5
●일정 및 목표
○프로젝트 기간 : 1년
○단기 목표 : 6개월 내 최초 모델 배포 및 서비스
○장기 목표 : 5개 모델 추가 배포 및 서비스

모델 및 데이터
○학습은 매일 수행되어야 함
○모델의 학습 데이터셋 양은 선형적으로 증가하고 있음
○비용 효율성 고려
○추론 결과 TTL 3일 (RPO, Recovery Point Objective)
○모델 장애 시 최대 3일 내 복구되어야 함(RTO, Recovery Time Objective)
○추론 결과가 없거나 장애로 인해 결과를 받지 못하는 경우 대응해야 함
○모델이 잘못된 예측을 하더라도 크리티컬한 서비스는 아님
○모델은 시간이 지남에 따라 정확도가 떨어질 수 있음
○타 모델 및 현재 모델에 대해서 빠른 확장과 업데이트가 가능해야 함

API 서버
○ TPS 요구사항(예상)
■ min : 100, avg: 300, max: 1000
○특정 시간의 트래픽 급증 패턴 대응 가능해야 함
○운영 비용 최소화
○비용 효율성 고려
○ p99 응답지연 500ms 이하
○ p95 응답지연 300ms 이하


Amazon 사례
○아마존 내부 서비스의 응답 시간 요구사항은 p999로 기술
○페이지 로드 시간이 100ms 증가할 때마다 매출 1% 손실
○페이지 로드 시간이 1s 증가하면 고객의 만족도는 16% 줄어듦


---

온라인 학습은 거의 쓰지 않음

### **온라인 학습 vs 오프라인 학습 (핵심 비교)**

| 구분 | **오프라인 학습 (Batch Learning)** | **온라인 학습 (Online Learning)** |
| --- | --- | --- |
| **데이터 처리** | 모든 데이터를 한 번에 모아서 학습. | 새로운 데이터가 들어올 때마다 조금씩 학습. |
| **학습 시점** | 주기적으로 (예: 매일, 매주) 재학습. 모델은 학습 후 고정. | 실시간으로 계속 학습하고 업데이트. 모델이 계속 변화. |
| **모델 변화** | 학습 후 고정된 상태. | 학습 후에도 계속 변화하고 업데이트. |
| **복잡성** | 상대적으로 단순하고 안정적. | 매우 복잡하고 구현 어려움 (고성능 인프라, 보안 문제). |
| **주요 사용처** | 대부분의 ML 서비스 (추천, 분류, 예측 등). | 데이터 변화가 극심하고 실시간 반영이 필수적인 경우 (사기 탐지, 초개인화 추천). |

### **온라인 추론 vs 오프라인 추론 (한눈에 비교)**

| 구분 | **온라인 추론 (Online Inference)** | **오프라인 추론 (Offline Inference)** |
| --- | --- | --- |
| **목적** | **실시간** 개별 요청에 대한 즉각적인 예측 | **주기적/배치** 대량 데이터에 대한 사전 예측 계산 |
| **응답 속도** | **매우 빠름 (수 ms ~ 수백 ms)**, 낮은 지연 시간 필수 | **빠른 응답 필요 없음**, 지연 시간 중요치 않음 |
| **데이터 처리** | 단일 요청 데이터 실시간 처리 | 대량의 데이터 배치(묶음) 처리 |
| **자원 사용** | 예측 시점에 자원 사용 (항시 대기) | 계산 시점에 집중적으로 자원 사용 |
| **예시** | 실시간 추천, 사기 탐지, 챗봇 답변 | 다음 날 수요 예측, 월별 고객 이탈 예측, 광고 타겟팅 |

### **다양한 추론 패턴 요약**

| 패턴 분류 | 패턴 이름 | 설명 |
| --- | --- | --- |
| **적합한 라이브러리 활용** | **전처리·추론 패턴** | 전처리(데이터 준비)와 추론(모델 예측)을 서로 다른 시스템에서 실행하여 각 작업에 맞는 라이브러리 사용 및 유지보수 용이. |
| **여러 모델 구성** | **직렬 마이크로서비스 패턴** | 여러 추론기로 구성된 시스템에서 추론기 간 의존성(순서)이 명확할 때 사용. |
|  | **병렬 마이크로서비스 패턴** | 독립적인 추론 모델을 동시에 수행할 때 사용. |
| **효율성/성능 최적화** | **시간차 추론 패턴** | 사용자 인터랙션이 중요한 애플리케이션에 추론기를 삽입하여, 응답 지연을 줄이고 사용자 경험을 개선. |
|  | **캐시 패턴** | 동일한 데이터에 대한 추론 요청 결과를 저장(캐시)해두어 중복 계산을 피하고 효율을 높임. |
| **대량 모델 관리** | **추론기 템플릿 패턴** | 동일한 입출력 형태를 가진 추론기를 대량으로 개발하고 배포할 때 사용. |
| **특수 환경** | **에지 AI 패턴** | 디바이스 자체에서 추론을 수행하거나, 보안/네트워크 제약으로 데이터 송수신이 어려울 때 사용. |
| **피해야 할 패턴 (안티 패턴)** | **온라인 빅사이즈 패턴** | 온라인 서비스나 실시간 처리 시스템에서 지연이 너무 큰(추론 시간이 오래 걸리는) 모델을 사용하는 경우. |
|  |  | **문제점**: 서비스가 요구하는 응답 시간과 모델의 추론 시간이 맞지 않음. |
|  |  | 배치 처리(한꺼번에 처리) 시 '총 추론 횟수 * 각 추론 시간'이 정해진 완료 시간을 초과하는 경우. |
|  | **올인원 패턴** | 여러 추론 모델을 가동하는 시스템에서 모든 모델이 하나의 서버에서만 가동되는 경우. |
|  |  | **문제점**: 한 모델에 문제가 생기면 전체 시스템에 영향. 자원 비효율적 사용 가능성. |

.
