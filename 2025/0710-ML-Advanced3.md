# Computer vision

컴퓨터가 사람처럼 눈으로 보고 사물을 인식하고 이해하게 만드는 기술

컴퓨터가 엄청나게 많은 이미지를 스스로 학습하면서 점점 더 똑똑해짐

이미지를 인식하고 분석해서 자율주행, 로봇 제어 같은 다양한 일을 할 수 있다.

### MLP(다층 퍼셉트론) 옛날 방식의 신경망

MLP는 input layer → hidden layers → output layer로 구성

입력층 → 은닉층 → 출력층

**입력층 뉴런 수는 표 데이터의 항목 수랑 같다.** 각 항목이 뉴런 하나에 대응되기 때문

MLP는 표 형태의 데이터(tabular data)를 학습하는 데 좋다.


### MLP를 컴퓨터 비전(CV)에 쓸 때의 문제점

MLP는 이미지를 처리할 때 2D 이미지를 1D로 펴야한다.(flatten)


2차원 이미지(N x M 픽셀)를 한 줄짜리 긴 1차원 데이터로 쭉 펴는 과정

오른쪽 예시는 28x28 픽셀짜리 숫자 이미지를 784x1 픽셀짜리 한 줄 데이터로 바꾸는 과정

### 이미지의 Locality 특성

**Spatial locality (공간적 지역성):** 같은 물체라도 이미지마다 크기가 다르다.
 Positional invariance:(위치 불변성) 같은 물체라도 다른 위치에 있을 수 있다.


사람 얼굴이 크게 보이거나 눈 부분만 확대되어 보일 수 있다.

MLP는 이미지 펴서 확인하는데 크기가 달라지면 다른 데이터로 인식할 가능성 큼

고양이 위치가 바뀌어도 같은 고양이지만 

MLP는 위치가 바뀌면 전혀 다른 데이터로 인식할 수 있어서 문제

# CNN이란 무엇인가?

## 합성곱 신경망 Convolution Filter

이미지의 특성을 고려해서 학습하도록 설계된 신경망

CNN은 MLP의 문제점 해결하기 위해 나옴
MLP가 여러 은닉층을 쌓아서 깊게 만들었듯이, 

CNN은 **합성곱 층을 여러 개 쌓아서 만든 깊은 신경망**

합성곱 필터 이용해 이미지 특징을 찾아내고 위치정보도 유지하며 학습한다.

CNN은 사진 속에서 고양이가 어디에 있든, 크기가 좀 다르든 잘 찾아내고 인식


컨볼루션 필터를 쓰면 이미지를 쫙 펴지 않고(flatten) 바로 계산할 수 있다.

물체의 구조나 주변 정보를 함께 연산할 수 있다.

같은 필터를 이미지 전체에 적용해서, 다른 위치에 똑같은 물체가 있어도 연산을 수행할 수 있다.


입력 → 특징 추출 → 분류

## 이미지 분류 경진대회 우승작품들

- 이미지 분류 경진대회 우승작품들
    
    ## 이미지 분류 경진대회
    
     ImageNet Large Scale Visual Recognition Challenge (ILSVRC)
    
    AlexNet
    
    2012년 ILSVRC 우승
    ● CNN을 사용한 최초의 모델이자 GPU 사용을 고려한 딥러닝 모델
    
    딥러닝과 CNN 연구가 폭발적으로 발전하는 계기
    
    
    VGG
    ● 2014년 ILSVRC 준우승
    ●구조가 단순하지만, 깊은 네트워크의 중요성을 알림
    
    층을 깊게 쌓는 것만으로도 이미지 분류 성능을 크게 향상시킬 수 있음을 증명한 모델이며, 
    
    이는 이후 더 깊은 딥러닝 네트워크 연구에 큰 영향을 줌
    
    
    ResNet
    ● 2015년 ILSVRC 우승
    ●네트워크를 깊게 쌓을 경우 생기는 문제점을 해결, 기존보다 더 깊은 네트워크를 제안 (최대 152 layer)
    
    잔차 연결'이라는 혁신적인 아이디어를 통해 딥러닝 모델을 엄청나게 깊게 쌓을 수 있게 만듦 
    
    모델의 성능 극대화, 딥러닝 발전에 큰 기여 한 중요한 모델
    
    
    EfficientNet
    ●기존 네트워크들이 가진 trade-off를 분석
    ●무작정 모델을 키우는 대신, 네트워크의 폭, 깊이, 해상도를 똑똑하게 조절해서 적은 자원으로도 매우 높은 성능을 낼 수 있음을 보여준 효율적인 모델
    
    
    .
    

## CNN의 한계점

1.이미지 안에서 멀리 떨어진 객체끼리 관련성을 파악하기가 어려움

예) 이미지 왼쪽 끝에 있는 사람과 오른쪽 끝에 있는 자전거가 서로 연관이 있다는 걸 CNN이 한 번에 알아내기 힘들다.

2.이미지의 각 파트가 이미지 이해에서 얼마나 중요한지, 

얼마나 서로 관련이 있는지 평가할 수 없음

예) CNN은 각 층에서 특징을 뽑아내긴 하지만, 이미지 전체 맥락에서 봤을 때 어떤 부분이 더 중요하고 어떤 부분들이 서로 연결되어 있는지 직관적으로 판단하기 어렵다.

이는 다음 세대 모델인 트랜스포머가 해결하려는 문제이기도 함

## Transformer

원래는 자연어처리(NLP) 작업을 위해 고안된 모델

주요 특징
장거리 의존성 Long-range dependency 

문장 안에서 멀리 떨어진 단어끼리도 서로 관계파악

셀프 어텐션 메커니즘 Self-attention mechanism 

각 단어들이 서로 얼마나 관련있는지 스스로 평가


### ViT & Swin

 트랜스포머 구조를 컴퓨터비전에 적용하여 해결한 ViT (Vision Transformer) 등장

더 나아가 CNN 특성을 ViT에 다시 적용한 Swin Transformer

Swin Transformer : 지역성과 전역적인 관계 파악 모두를 잘하도록 만든 모델

기존의 CNN이 이미지의 '지역성'에 집중했다면, 

ViT는 이미지를 여러 조각(패치)으로 나눈 다음, 트랜스포머의 셀프 어텐션 메커니즘을 이용

각 조각들이 이미지 전체에서 어떤 관계를 가지는지 파악하는 방식으로 작동


요약 정리

| 특징 | 트랜스포머 (Transformer) | ViT (Vision Transformer) | Swin Transformer |
| --- | --- | --- | --- |
| **등장 배경** | 원래 자연어(텍스트) 처리를 위해 만들어짐 | 트랜스포머를 이미지 처리(컴퓨터 비전)에 적용 | ViT의 한계를 보완하고 CNN의 장점까지 합침 |
| **주요 아이디어** | 셀프 어텐션(Self-attention): 멀리 있는 관계 파악 | 이미지를 '패치'로 나누어 텍스트처럼 처리 | '계층적 구조'와 '이동 윈도우'로 지역성 보완 |
| **이미지 처리 방식** | (원본이 텍스트라 해당 없음) | 이미지를 조각(패치) 내서 각 조각 간 관계 파악 | 작은 패치 그룹(윈도우) 안에서 어텐션, 윈도우 이동 |
| **강점** | 문맥 파악, 장거리 의존성(멀리 있는 단어 관계) 파악 | 전역적인 관계 파악 (이미지 전체 맥락) | 지역적 특징과 전역적 관계 모두 잘 파악, 효율성 |
| **약점** | (이미지 처리 관점에서는 직접 적용 어려움) | 이미지의 '지역성' 정보 손실 가능성 | ViT보다는 복잡하지만, 전반적으로 성능 우수 |
| **핵심 기여** | 셀프 어텐션이라는 혁신적인 메커니즘 제시 | 트랜스포머의 이미지 비전 적용 가능성 증명 | 트랜스포머와 CNN 장점을 결합한 새로운 발전 제시 |

결론

**트랜스포머**는 텍스트 분야에서 혁신적인 '셀프 어텐션'으로 장거리 관계를 잘 파악하는 모델
**ViT**는 이미지에 적용해 전체적인 관계를 보게 해줬지만, 작은 부분 특징을 놓침
S**win Transformer**는 ViT의 약점을 보완, 트랜스포머의 장점(전역적 관계 파악)에 CNN의 장점(지역적 특징 파악)까지 더해 이미지 처리 성능을 더 높인 모델
